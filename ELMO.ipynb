{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdf12b0",
   "metadata": {
    "papermill": {
     "duration": 0.006044,
     "end_time": "2024-04-17T12:10:06.933862",
     "exception": false,
     "start_time": "2024-04-17T12:10:06.927818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading Dataset , Cleaning, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c2a6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:10:06.947071Z",
     "iopub.status.busy": "2024-04-17T12:10:06.946741Z",
     "iopub.status.idle": "2024-04-17T12:10:52.286277Z",
     "shell.execute_reply": "2024-04-17T12:10:52.285284Z"
    },
    "papermill": {
     "duration": 45.34877,
     "end_time": "2024-04-17T12:10:52.288863",
     "exception": false,
     "start_time": "2024-04-17T12:10:06.940093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e78ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_csv_file = 'train.csv'\n",
    "test_csv_file = 'test.csv'\n",
    "train_data = pd.read_csv(train_csv_file)\n",
    "\n",
    "dev_set_size = 7600\n",
    "train_set = train_data.iloc[dev_set_size:]\n",
    "dev_set = train_data.iloc[:dev_set_size]\n",
    "\n",
    "train_sentences = train_set['Description'].tolist()\n",
    "train_labels = train_set['Class Index'].tolist()\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "    tokens = sentence.split()\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_sentences_cleaned = [clean_sentence(sentence) for sentence in train_sentences]\n",
    "train_sentences_tokenized = [word_tokenize(sentence) for sentence in train_sentences_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae1fe77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:10:52.303195Z",
     "iopub.status.busy": "2024-04-17T12:10:52.302828Z",
     "iopub.status.idle": "2024-04-17T12:10:52.310245Z",
     "shell.execute_reply": "2024-04-17T12:10:52.309416Z"
    },
    "papermill": {
     "duration": 0.017078,
     "end_time": "2024-04-17T12:10:52.312327",
     "exception": false,
     "start_time": "2024-04-17T12:10:52.295249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Sentences (tokenized):\n",
      "[['such', 'an', 'embarrassment', 'of', 'riches', 'apple', 'macintosh', 'users', 'have', 'two', 'new', 'web', 'browsers', 'to', 'choose', 'from', 'it', 's', 'a', 'curious', 'market', 'all', 'macs', 'come', 'with', 'two', 'free', 'browsers', 'microsoft', 's', 'internet', 'explorer', 'and', 'apple', 's', 'own', 'slick', 'and', 'elegant', 'safari'], ['the', 'women', 's', 'gold', 'medallist', 'in', 'shot', 'put', 'irina', 'korzhanenko', 'has', 'been', 'disqualified', 'from', 'the', 'olympics', 'and', 'stripped', 'of', 'her', 'medal', 'after', 'testing', 'positive', 'for', 'doping']]\n",
      "Train Set Labels:\n",
      "[4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set Sentences (tokenized):\")\n",
    "print(train_sentences_tokenized[:2])\n",
    "print(\"Train Set Labels:\")\n",
    "print(train_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ee7484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:10:52.325797Z",
     "iopub.status.busy": "2024-04-17T12:10:52.325469Z",
     "iopub.status.idle": "2024-04-17T12:10:52.330420Z",
     "shell.execute_reply": "2024-04-17T12:10:52.329434Z"
    },
    "papermill": {
     "duration": 0.0147,
     "end_time": "2024-04-17T12:10:52.333228",
     "exception": false,
     "start_time": "2024-04-17T12:10:52.318528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 112400\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_dataset size: {len(train_sentences_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb15a7c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:10:52.350732Z",
     "iopub.status.busy": "2024-04-17T12:10:52.349903Z",
     "iopub.status.idle": "2024-04-17T12:10:54.567437Z",
     "shell.execute_reply": "2024-04-17T12:10:54.566429Z"
    },
    "papermill": {
     "duration": 2.227903,
     "end_time": "2024-04-17T12:10:54.569761",
     "exception": false,
     "start_time": "2024-04-17T12:10:52.341858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_words = [word for sentence in train_sentences_tokenized for word in sentence]\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "vocab = ['<UNK>', '<PAD>'] + [word for word, count in word_counts.items()]\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "def sentence_to_indices(sentence, word2idx):\n",
    "    return [word2idx.get(word, word2idx['<UNK>']) for word in sentence]\n",
    "\n",
    "train_indices = [sentence_to_indices(sentence, word2idx) for sentence in train_sentences_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82759ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:10:54.583749Z",
     "iopub.status.busy": "2024-04-17T12:10:54.583403Z",
     "iopub.status.idle": "2024-04-17T12:10:54.588624Z",
     "shell.execute_reply": "2024-04-17T12:10:54.587736Z"
    },
    "papermill": {
     "duration": 0.015,
     "end_time": "2024-04-17T12:10:54.591134",
     "exception": false,
     "start_time": "2024-04-17T12:10:54.576134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Indices:\n",
      "[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 11, 27, 14, 28, 19, 29, 30, 31, 7, 19, 32, 33, 31, 34, 35], [36, 37, 19, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 17, 36, 48, 31, 49, 5, 50, 51, 52, 53, 54, 55, 56]]\n",
      "Train Set Labels:\n",
      "[4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Indices:\")\n",
    "print(train_indices[:2]) \n",
    "print(\"Train Set Labels:\")\n",
    "print(train_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a44d50a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:10:54.605511Z",
     "iopub.status.busy": "2024-04-17T12:10:54.604882Z",
     "iopub.status.idle": "2024-04-17T12:11:04.283134Z",
     "shell.execute_reply": "2024-04-17T12:11:04.282330Z"
    },
    "papermill": {
     "duration": 9.68816,
     "end_time": "2024-04-17T12:11:04.285524",
     "exception": false,
     "start_time": "2024-04-17T12:10:54.597364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_all_sentences = [idx for sentence in train_indices for idx in sentence]\n",
    "def create_ngrams(sequence, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(sequence) - n + 1):\n",
    "        ngram = sequence[i:i + n]\n",
    "        ngrams.append(ngram)\n",
    "    return torch.tensor(ngrams, dtype=torch.long)\n",
    "\n",
    "ngram_size = 6\n",
    "train_data = create_ngrams(train_all_sentences, ngram_size)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(train_data[:100000]), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40645346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:04.300219Z",
     "iopub.status.busy": "2024-04-17T12:11:04.299337Z",
     "iopub.status.idle": "2024-04-17T12:11:04.304656Z",
     "shell.execute_reply": "2024-04-17T12:11:04.303677Z"
    },
    "papermill": {
     "duration": 0.015328,
     "end_time": "2024-04-17T12:11:04.307167",
     "exception": false,
     "start_time": "2024-04-17T12:11:04.291839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ngrams: 3374491\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Ngrams: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba49671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:04.322084Z",
     "iopub.status.busy": "2024-04-17T12:11:04.321495Z",
     "iopub.status.idle": "2024-04-17T12:11:04.339956Z",
     "shell.execute_reply": "2024-04-17T12:11:04.338932Z"
    },
    "papermill": {
     "duration": 0.028332,
     "end_time": "2024-04-17T12:11:04.342108",
     "exception": false,
     "start_time": "2024-04-17T12:11:04.313776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4, 5, 6, 7],\n",
      "        [3, 4, 5, 6, 7, 8]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:2])\n",
    "print(train_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dad16e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:04.357810Z",
     "iopub.status.busy": "2024-04-17T12:11:04.357217Z",
     "iopub.status.idle": "2024-04-17T12:11:04.413253Z",
     "shell.execute_reply": "2024-04-17T12:11:04.412259Z"
    },
    "papermill": {
     "duration": 0.066096,
     "end_time": "2024-04-17T12:11:04.415347",
     "exception": false,
     "start_time": "2024-04-17T12:11:04.349251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90220e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:04.431165Z",
     "iopub.status.busy": "2024-04-17T12:11:04.430815Z",
     "iopub.status.idle": "2024-04-17T12:11:17.191181Z",
     "shell.execute_reply": "2024-04-17T12:11:17.190381Z"
    },
    "papermill": {
     "duration": 12.771829,
     "end_time": "2024-04-17T12:11:17.193670",
     "exception": false,
     "start_time": "2024-04-17T12:11:04.421841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_glove_model(file_path):\n",
    "    word_vectors = {}\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = [float(val) for val in values[1:]]\n",
    "            word_vectors[word] = vector\n",
    "\n",
    "    return word_vectors\n",
    "\n",
    "glove_file_path = './glove.6B.100d.txt'\n",
    "glove_dict = load_glove_model(glove_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c5bdd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:17.208510Z",
     "iopub.status.busy": "2024-04-17T12:11:17.208138Z",
     "iopub.status.idle": "2024-04-17T12:11:17.214433Z",
     "shell.execute_reply": "2024-04-17T12:11:17.213521Z"
    },
    "papermill": {
     "duration": 0.016251,
     "end_time": "2024-04-17T12:11:17.216612",
     "exception": false,
     "start_time": "2024-04-17T12:11:17.200361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(glove_dict):\n",
    "    weights_matrix = torch.randn((len(vocab), 100))\n",
    "    words_found = 0\n",
    "    for i, word in enumerate(vocab):\n",
    "        try:\n",
    "            weights_matrix[i] = torch.tensor(glove_dict[word])\n",
    "            words_found += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return weights_matrix, words_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d9016a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:17.232018Z",
     "iopub.status.busy": "2024-04-17T12:11:17.231161Z",
     "iopub.status.idle": "2024-04-17T12:11:19.471921Z",
     "shell.execute_reply": "2024-04-17T12:11:19.471084Z"
    },
    "papermill": {
     "duration": 2.250997,
     "end_time": "2024-04-17T12:11:19.474461",
     "exception": false,
     "start_time": "2024-04-17T12:11:17.223464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_matrix, words_found = create_embedding_matrix(glove_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed492ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:19.489277Z",
     "iopub.status.busy": "2024-04-17T12:11:19.488931Z",
     "iopub.status.idle": "2024-04-17T12:11:19.493959Z",
     "shell.execute_reply": "2024-04-17T12:11:19.493009Z"
    },
    "papermill": {
     "duration": 0.014965,
     "end_time": "2024-04-17T12:11:19.496031",
     "exception": false,
     "start_time": "2024-04-17T12:11:19.481066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 81098\n",
      "words found in glove embedding: 50707\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size:\", len(vocab))\n",
    "print(f\"words found in glove embedding: {words_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59426d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:19.510561Z",
     "iopub.status.busy": "2024-04-17T12:11:19.510236Z",
     "iopub.status.idle": "2024-04-17T12:11:19.535347Z",
     "shell.execute_reply": "2024-04-17T12:11:19.534427Z"
    },
    "papermill": {
     "duration": 0.034947,
     "end_time": "2024-04-17T12:11:19.537448",
     "exception": false,
     "start_time": "2024-04-17T12:11:19.502501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ELMo(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix):\n",
    "        super(ELMo, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "\n",
    "        self.lstm_forward1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm_forward2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.linear_mode1 = nn.Linear(2*hidden_dim, vocab_size)\n",
    "\n",
    "        self.lstm_backward1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm_backward2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.linear_mode2 = nn.Linear(2*hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_data, mode):\n",
    "        if mode == 1:\n",
    "            forward_embed = self.embedding(input_data)\n",
    "            forward_lstm1, _ = self.lstm_forward1(forward_embed) \n",
    "            forward_lstm2, _ = self.lstm_forward2(forward_lstm1)\n",
    "            lstm_concat = torch.cat((forward_lstm1, forward_lstm2), dim=-1)\n",
    "            output = self.linear_mode1(lstm_concat)\n",
    "            return output\n",
    "        \n",
    "        elif mode == 2:\n",
    "            backward_embed = self.embedding(input_data)\n",
    "            backward_lstm1, _ = self.lstm_backward1(backward_embed) \n",
    "            backward_lstm2, _ = self.lstm_backward2(backward_lstm1)\n",
    "            lstm_concat = torch.cat((backward_lstm1, backward_lstm2), dim=-1)\n",
    "            output = self.linear_mode2(lstm_concat)\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d91ce221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:19.551998Z",
     "iopub.status.busy": "2024-04-17T12:11:19.551697Z",
     "iopub.status.idle": "2024-04-17T12:11:20.235123Z",
     "shell.execute_reply": "2024-04-17T12:11:20.234276Z"
    },
    "papermill": {
     "duration": 0.693318,
     "end_time": "2024-04-17T12:11:20.237542",
     "exception": false,
     "start_time": "2024-04-17T12:11:19.544224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size =  len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 100\n",
    "\n",
    "# Define the ELMo model\n",
    "elmo = ELMo(vocab_size, embedding_dim, hidden_dim, embedding_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9ec45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:20.253139Z",
     "iopub.status.busy": "2024-04-17T12:11:20.252809Z",
     "iopub.status.idle": "2024-04-17T12:11:20.260824Z",
     "shell.execute_reply": "2024-04-17T12:11:20.259910Z"
    },
    "papermill": {
     "duration": 0.01794,
     "end_time": "2024-04-17T12:11:20.262776",
     "exception": false,
     "start_time": "2024-04-17T12:11:20.244836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mode1(model, mode, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for inputs in tqdm(train_loader):\n",
    "        inputs = inputs[0]\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if mode == 2:\n",
    "            inputs = torch.flip(inputs, dims=[1])\n",
    "\n",
    "        input_seq = inputs[:, :5]\n",
    "        target_seq = inputs[:, 1:]\n",
    "        outputs = model(input_seq, mode=mode)\n",
    "        loss = criterion(outputs.permute(0, 2, 1), target_seq)  # Permute because outputs is (batch_size, seq_len, embed_dim) and target_Seq is (batch_size, seq_len).\n",
    "        total_loss += loss.item()\n",
    "        total_tokens += target_seq.numel()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / total_tokens\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "383a6a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:11:20.277980Z",
     "iopub.status.busy": "2024-04-17T12:11:20.277620Z",
     "iopub.status.idle": "2024-04-17T12:14:00.483629Z",
     "shell.execute_reply": "2024-04-17T12:14:00.482534Z"
    },
    "papermill": {
     "duration": 160.21731,
     "end_time": "2024-04-17T12:14:00.486934",
     "exception": false,
     "start_time": "2024-04-17T12:11:20.269624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:40<00:00, 77.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 (Mode 1) - Train Loss: 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 (Mode 1) - Train Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 (Mode 1) - Train Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 (Mode 1) - Train Loss: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(elmo.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_mode1 = train_mode1(elmo, 1, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} (Mode 1) - Train Loss: {train_loss_mode1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f97ffe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:14:00.787634Z",
     "iopub.status.busy": "2024-04-17T12:14:00.787061Z",
     "iopub.status.idle": "2024-04-17T12:16:37.909352Z",
     "shell.execute_reply": "2024-04-17T12:16:37.908439Z"
    },
    "papermill": {
     "duration": 157.251326,
     "end_time": "2024-04-17T12:16:37.912650",
     "exception": false,
     "start_time": "2024-04-17T12:14:00.661324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 (Mode 2) - Train Loss: 0.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 (Mode 2) - Train Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 (Mode 2) - Train Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:39<00:00, 79.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 (Mode 2) - Train Loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(elmo.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_mode1 = train_mode1(elmo, 2, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} (Mode 2) - Train Loss: {train_loss_mode1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ef074",
   "metadata": {
    "papermill": {
     "duration": 0.242201,
     "end_time": "2024-04-17T12:16:38.399744",
     "exception": false,
     "start_time": "2024-04-17T12:16:38.157543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3deb3d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:16:38.891088Z",
     "iopub.status.busy": "2024-04-17T12:16:38.890706Z",
     "iopub.status.idle": "2024-04-17T12:16:39.214830Z",
     "shell.execute_reply": "2024-04-17T12:16:39.213852Z"
    },
    "papermill": {
     "duration": 0.572835,
     "end_time": "2024-04-17T12:16:39.217191",
     "exception": false,
     "start_time": "2024-04-17T12:16:38.644356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = 'pretrained_elmo'\n",
    "torch.save(elmo.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4816991,
     "sourceId": 8145896,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4817046,
     "sourceId": 8145968,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 398.140257,
   "end_time": "2024-04-17T12:16:42.220902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T12:10:04.080645",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
